{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from os import walk, path\n",
    "import flowiz\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from unet_utils import Down, Up, DoubleConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class FlowDataset(Dataset):\n",
    "    \"\"\"Flow dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir='./data', transform=None, copy_from = None, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(*args, **kwargs)\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images_paths = []\n",
    "        self.flow_paths = []\n",
    "\n",
    "        if copy_from:\n",
    "            self.images_paths = copy_from[0]\n",
    "            self.flow_paths = copy_from[1]\n",
    "        else:\n",
    "            for pardir, dirs, files in walk(path.join(root_dir, 'images')):\n",
    "                image_name = path.basename(pardir)\n",
    "                if not (image_name.startswith('IM') and '_' not in image_name):\n",
    "                    continue\n",
    "\n",
    "                # We have an image\n",
    "                for frame_name in files:\n",
    "                    frame_number = frame_name[6:10]\n",
    "                    flow_name = 'frameGT_' + str(frame_number) + '.flo'\n",
    "                    flow_path = path.join(root_dir, 'gt_flow', image_name, flow_name)\n",
    "                    frame_path = path.join(pardir, frame_name)\n",
    "\n",
    "                    if not path.exists(flow_path) or not path.exists(frame_path):\n",
    "                        continue\n",
    "\n",
    "                    self.images_paths.append(frame_path)\n",
    "                    self.flow_paths.append(flow_path)\n",
    "\n",
    "            self.images_paths = np.asarray(self.images_paths)\n",
    "            self.flow_paths = np.asarray(self.flow_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print('Called __getitem__')\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        print('Loading', idx)\n",
    "        image_path, flow_path = self.images_paths[idx], self.flow_paths[idx]\n",
    "        print(image_path)\n",
    "        print(flow_path)\n",
    "        image = io.imread(image_path)\n",
    "        flow = flowiz.convert_from_file(flow_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, flow\n",
    "\n",
    "    def slice(self, limit: int):\n",
    "        return (\n",
    "            FlowDataset(root_dir=self.root_dir, transform=self.transform, copy_from=[\n",
    "                self.images_paths[:limit],\n",
    "                self.flow_paths[:limit],\n",
    "            ]),\n",
    "            FlowDataset(root_dir=self.root_dir, transform=self.transform, copy_from=[\n",
    "                self.images_paths[limit:],\n",
    "                self.flow_paths[limit:],\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    def random_split(self, size: int):\n",
    "        zipped = list(zip(self.images_paths, self.flow_paths))\n",
    "        shuffle(zipped)\n",
    "        img_paths, flow_paths = list(zip(*zipped))\n",
    "\n",
    "        return FlowDataset(root_dir=self.root_dir, transform=self.transform, copy_from=[img_paths, flow_paths]).slice(size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class LitUNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes: int,\n",
    "            *,\n",
    "            num_layers: int = 5,\n",
    "            features_start: int = 64,\n",
    "            batch_size: int = 10,\n",
    "            num_workers: int = 10,\n",
    "            bilinear: bool = False,\n",
    "\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Paper: `U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        <https://arxiv.org/abs/1505.04597>`_\n",
    "        Paper authors: Olaf Ronneberger, Philipp Fischer, Thomas Brox\n",
    "        Implemented by:\n",
    "            - `Annika Brundyn <https://github.com/annikabrundyn>`_\n",
    "            - `Akshay Kulkarni <https://github.com/akshaykvnit>`_\n",
    "        Args:\n",
    "            num_classes: Number of output classes required\n",
    "            num_layers: Number of layers in each side of U-net (default 5)\n",
    "            features_start: Number of features in first layer (default 64)\n",
    "            bilinear (bool): Whether to use bilinear interpolation or transposed convolutions (default) for upsampling.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        layers = [DoubleConv(3, features_start)]\n",
    "\n",
    "        feats = features_start\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(Down(feats, feats * 2))\n",
    "            feats *= 2\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(Up(feats, feats // 2, bilinear))\n",
    "            feats //= 2\n",
    "\n",
    "        # TODO: change the convolution so that it predicts masks and not classes\n",
    "        layers.append(nn.Conv2d(feats, num_classes, kernel_size=1))\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.data = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        xi = [self.layers[0](x)]\n",
    "\n",
    "        # Down path\n",
    "        for layer in self.layers[1:self.num_layers]:\n",
    "            xi.append(layer(xi[-1]))\n",
    "\n",
    "        # Up path\n",
    "        for i, layer in enumerate(self.layers[self.num_layers:-1]):\n",
    "            xi[-1] = layer(xi[-1], xi[-2 - i])\n",
    "\n",
    "        pred = self.layers[-1](xi[-1])\n",
    "\n",
    "        return pred\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_loss(logits, y):\n",
    "        # TODO: Somehow, calculate loss using Low Entropy Motion Loss\n",
    "        loss = ...\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "\n",
    "        loss = self.calculate_loss(logits, y)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def general_step(self, step_name, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.calculate_loss(logits, y)\n",
    "\n",
    "        self.log(step_name + '_loss', loss, prog_bar=True)\n",
    "\n",
    "        # TODO: Calculate accuracy maybe ?\n",
    "        # acc = ...\n",
    "        # self.log(step_name + '_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        self.general_step('val', batch, batch_nb)\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        self.general_step('test', batch, batch_nb)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # TODO: Find some optimizer\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        pass\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "    def setup(self, stage=None):\n",
    "        print('setup')\n",
    "        if self.data is None:\n",
    "            self.data = FlowDataset()\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        train_size = int(len(self.data) * 0.9)\n",
    "        train_data, test_data = self.data.slice(train_size)\n",
    "\n",
    "        if stage == 'fit' or stage is None:\n",
    "            train_size = int(len(train_data) * 0.9)\n",
    "\n",
    "            self.data_train, self.data_val = train_data.random_split(train_size)\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.data_test = test_data\n",
    "\n",
    "        print('setup_end')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        print('train_dl')\n",
    "        dl = DataLoader(self.data_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers,\n",
    "                          pin_memory=True)\n",
    "        print('train_dl end')\n",
    "        return dl\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        print('val_dl')\n",
    "        dl = DataLoader(self.data_val, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers,\n",
    "                          pin_memory=True)\n",
    "        print('val_dl end')\n",
    "        return dl\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers,\n",
    "                          pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = LitUNet(5, num_workers=0, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=15, progress_bar_refresh_rate=20,\n",
    "    precision=16,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | layers | ModuleList | 31.0 M\n",
      "--------------------------------------\n",
      "31.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup\n",
      "setup_end\n",
      "val_dl\n",
      "val_dl end\n",
      "Called __getitem__\n",
      "Loading 0\n",
      "./data\\images\\IM04\\frame_0035.png\n",
      "./data\\gt_flow\\IM04\\frameGT_0035.flo\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c6b2e5e2bb84b7ba1a384e218cd0168"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 720, 1280, 3] to have 3 channels, but got 720 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-004bebc802c7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001B[0m\n\u001B[0;32m    508\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'on_fit_start'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    509\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 510\u001B[1;33m         \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maccelerator_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    511\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maccelerator_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mteardown\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msetup_trainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_or_test\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mteardown\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001B[0m in \u001B[0;36mtrain_or_test\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     72\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_loop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msetup_training\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m             \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     75\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    530\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    531\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 532\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_sanity_check\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    533\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    534\u001B[0m         \u001B[1;31m# set stage for logging\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001B[0m in \u001B[0;36mrun_sanity_check\u001B[1;34m(self, ref_model)\u001B[0m\n\u001B[0;32m    729\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    730\u001B[0m             \u001B[1;31m# run eval step\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 731\u001B[1;33m             \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meval_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_batches\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_sanity_val_batches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    732\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    733\u001B[0m             \u001B[1;31m# allow no returns from eval\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001B[0m in \u001B[0;36mrun_evaluation\u001B[1;34m(self, max_batches, on_epoch)\u001B[0m\n\u001B[0;32m    641\u001B[0m                 \u001B[1;31m# lightning module methods\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    642\u001B[0m                 \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"evaluation_step_and_end\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 643\u001B[1;33m                     \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluation_loop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluation_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataloader_idx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    644\u001B[0m                     \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluation_loop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluation_step_end\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    645\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\trainer\\evaluation_loop.py\u001B[0m in \u001B[0;36mevaluation_step\u001B[1;34m(self, batch, batch_idx, dataloader_idx)\u001B[0m\n\u001B[0;32m    169\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    170\u001B[0m             \u001B[0mmodel_ref\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_current_fx_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"validation_step\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 171\u001B[1;33m             \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maccelerator_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalidation_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    172\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    173\u001B[0m         \u001B[1;31m# capture any logged information\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\accelerators\\gpu_accelerator.py\u001B[0m in \u001B[0;36mvalidation_step\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mvalidation_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalidation_step\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtest_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\pytorch_lightning\\accelerators\\gpu_accelerator.py\u001B[0m in \u001B[0;36m_step\u001B[1;34m(self, model_step, args)\u001B[0m\n\u001B[0;32m     61\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mamp_backend\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mAMPType\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNATIVE\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mamp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautocast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-10-c4a786f80f10>\u001B[0m in \u001B[0;36mvalidation_step\u001B[1;34m(self, batch, batch_nb)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mvalidation_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_nb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgeneral_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'val'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_nb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     93\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtest_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_nb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-10-c4a786f80f10>\u001B[0m in \u001B[0;36mgeneral_step\u001B[1;34m(self, step_name, batch, batch_nb)\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mgeneral_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_nb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 80\u001B[1;33m         \u001B[0mlogits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     81\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalculate_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-10-c4a786f80f10>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m         \u001B[0mxi\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m         \u001B[1;31m# Down path\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\self-supervised-segmentation\\unet_utils.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 117\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    118\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    422\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 423\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    424\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    425\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\self-supervised-segmentation\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight)\u001B[0m\n\u001B[0;32m    417\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    418\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m--> 419\u001B[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001B[0m\u001B[0;32m    420\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[0;32m    421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 720, 1280, 3] to have 3 channels, but got 720 channels instead"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8b3d558b",
   "language": "python",
   "display_name": "PyCharm (self-supervised-segmentation)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}